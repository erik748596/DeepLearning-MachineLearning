{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erik748596/DeepLearning-MachineLearning/blob/master/cars_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaxoqFkMAVhJ",
        "outputId": "e2b7e430-031f-4524-f42d-187f15dce34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/Cars\n"
          ]
        }
      ],
      "source": [
        "# Mount to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Move to your current working directory\n",
        "%cd drive/MyDrive/Colab\\ Notebooks/Cars"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3w1ojYmO4Xs",
        "outputId": "daee1e0d-3514-4c10-e39b-105be91edb93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cars_segmentation.ipynb\t\t   merge.ipynb\tsmall_train_masks\n",
            "「cars_segmentation.ipynb」的副本  small_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s3gL3LFHAed8"
      },
      "outputs": [],
      "source": [
        "# Import all the packages\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OQospNIGB9CM"
      },
      "outputs": [],
      "source": [
        "# Build one of the main components - DoubleConv - for UNet\n",
        "class DoubleConv(nn.Module):\n",
        "  def __init__(self, in_channels,out_channels):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3,1,1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, 3,1,1,bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rZSFGD-sCHtV"
      },
      "outputs": [],
      "source": [
        "# Build UNet from scrach\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self, in_channels=3, out_channels=1, features=[64,128,256,512]):\n",
        "    super(UNet, self).__init__()#啟動nn.Module\n",
        "    self.downs = nn.ModuleList()\n",
        "    self.ups = nn.ModuleList()#興建encoder decoder\n",
        "    for feature in features:\n",
        "      # 3轉64 64轉128 128轉256 256轉512\n",
        "      self.downs.append(DoubleConv(in_channels, feature))\n",
        "      in_channels = feature\n",
        "    # 512 to 1024\n",
        "    # features的最後一個\n",
        "    self.bottleneck = DoubleConv(features[-1],features[-1]*2)\n",
        "    # feature = 512\n",
        "    for feature in reversed(features):\n",
        "      self.ups.append(nn.ConvTranspose2d(feature*2,feature , 2,2))#kernel size 跟 stride\n",
        "      self.ups.append(DoubleConv(feature*2,feature))\n",
        "    self.final_conv = nn.Conv2d(feature,out_channels , 1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    skip_connections = []\n",
        "    for down in self.downs:\n",
        "      x = down(x)\n",
        "      skip_connections.append(x)\n",
        "      x = F.max_pool2d(x,(2,2))\n",
        "    x = self.bottleneck(x)\n",
        "    skip_connections.reverse()\n",
        "    for i in range(0, len(self.ups),2):\n",
        "      x = self.ups[i](x)\n",
        "      skip_connection = skip_connections[i//2]\n",
        "      concat = torch.cat((skip_connection , x), dim=1 ) # N * C * H * W ,channel=1\n",
        "      x = self.ups[i+1](concat)\n",
        "    return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO5Xg0pUJbNp",
        "outputId": "8096ba46-ba6c-4695-eec5-c9e89feeea1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 240, 160])\n"
          ]
        }
      ],
      "source": [
        "# Create an UNet model object\n",
        "model = UNet()\n",
        "toy_data = torch.ones((16,3,240,160))\n",
        "output = model(toy_data)\n",
        "print(output.shape)\n",
        "\n",
        "# Move the model to GPU\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E5K3gqBd0_7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a2aa6e-c82d-41d6-e98a-1188f3adb4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ILgSgfqFJidq"
      },
      "outputs": [],
      "source": [
        "# Build CustomDataset for loading data from Google Drive\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, image_dir, mask_dir, transform):\n",
        "    super().__init__()\n",
        "    self.image_dir = image_dir\n",
        "    self.mask_dir = mask_dir\n",
        "    self.transform = transform\n",
        "    self.images = os.listdir(image_dir)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_path = os.path.join(self.image_dir, self.images[index])\n",
        "    mask_path = os.path.join(self.mask_dir, self.images[index].replace('.jpg','_mask.gif'))\n",
        "    image = np.array(Image.open(image_path))\n",
        "    mask = np.array(Image.open(mask_path).convert('L'))#轉成灰階\n",
        "      # 將遮罩圖像二值化\n",
        "    mask[mask > 0] = 1\n",
        "    return self.transform(image), self.transform(mask)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5eqoqZEaHUzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ed8f48-c6a4-4328-8ac0-3f2af41d8256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Check the device we are using is GPU or CPU\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sBoa09DRHUtm"
      },
      "outputs": [],
      "source": [
        "# Constants for UNet model training process\n",
        "BATCH_SIZE = 16\n",
        "NUM_EPOCHS = 1\n",
        "IMG_WIDTH = 240\n",
        "IMG_HEIGHT = 160"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rd67NulqHUly"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "all_data = CustomDataset('small_train', 'small_train_masks', T.Compose([T.ToTensor(), T.Resize((IMG_HEIGHT, IMG_WIDTH))]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GwM6Vz5NKtfm"
      },
      "outputs": [],
      "source": [
        "# Split data into train and val\n",
        "train_data, val_data = torch.utils.data.random_split(all_data, [0.7, 0.3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Gp2ZXGzHLYmt"
      },
      "outputs": [],
      "source": [
        "# Create loader for mini-batch gradient descent\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jEJ-RbO6UzJP"
      },
      "outputs": [],
      "source": [
        "# The loss function for bianry classification\n",
        "loss_function = nn.BCELoss()\n",
        "\n",
        "# Choosing Adam as our optimizer\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fYS30O-dSl0L"
      },
      "outputs": [],
      "source": [
        "def train(model, num_epochs, train_loader, optimizer, print_every=30):\n",
        "  for epoch in range(num_epochs):\n",
        "    for count, (x, y) in enumerate(train_loader):\n",
        "      model.train()\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      out = model(x)\n",
        "      if count % print_every == 0:\n",
        "        eval(model, val_loader, epoch)\n",
        "      out = torch.sigmoid(out)\n",
        "      loss = loss_function(out, y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4weW5Wi8RWMW"
      },
      "outputs": [],
      "source": [
        "def eval(model, val_loader, epoch):\n",
        "  model.eval()\n",
        "  num_correct = 0\n",
        "  num_pixels = 0\n",
        "  with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      out_img = model(x)\n",
        "      probability = torch.sigmoid(out_img)\n",
        "      predictions = probability>0.5\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_pixels += BATCH_SIZE*IMG_WIDTH*IMG_HEIGHT\n",
        "  print(f'Epoch[{epoch+1}] Acc: {num_correct/num_pixels}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8rcL1usEWTHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbf515f-0ff0-4cd7-a989-208ff2feafcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1] Acc: 0.7743916511535645\n",
            "Epoch[1] Acc: 0.7742056250572205\n",
            "Epoch[1] Acc: 0.7743327617645264\n"
          ]
        }
      ],
      "source": [
        "train(model, NUM_EPOCHS, train_loader, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLmSx5eZGq8t"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}